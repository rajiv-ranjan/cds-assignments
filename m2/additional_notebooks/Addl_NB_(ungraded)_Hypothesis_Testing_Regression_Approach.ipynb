{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7rc1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aUUu9l_JfJ92"},"source":["# Advanced Certification Program in Computational Data Science\n","## A program by IISc and TalentSprint\n","### Additional Notebook (Ungraded): Hypothesis Testing - Regression Approach"]},{"cell_type":"markdown","metadata":{"id":"SL3yrUc-XrLS"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"nq2_Otle4nO2"},"source":["\n","\n","At the end of this Addition Notebook, you will be able to :\n","\n","\n","* Have a very surface and high-level level understanding of A/B Testing - a Regression Approach way to compare two or more versions (A or B?)\n","\n","* Determine not only which one (A or B) performs better but also to understand if the difference between two of them is statistically significant.\n","\n","* Learn how to set up and interpret a regression model specifically designed for comparing groups in A/B testing scenarios.\n","\n","* Gain skills to interpret the regression coefficients and p-values to draw meaningful conclusions about the performance differences and their statistical significance.\n","\n","\n","\n"]},{"cell_type":"markdown","source":["## Introduction"],"metadata":{"id":"92Ff_XtzI0f1"}},{"cell_type":"markdown","source":["A/B tests are very commonly performed by data analysts and data scientists. It is important to get some practice working with these difficulties.\n","\n","A/B testing is a crucial technique in data-driven decision-making, yet it often lacks comprehensive exploration. This notebook aims to address this gap by providing a consolidated overview of A/B testing principles and practices.\n","\n","For this Additional Notebook, you will be working to understand the results of an A/B test run by an e-commerce website. Your goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision."],"metadata":{"id":"M19d-lHWImDi"}},{"cell_type":"markdown","metadata":{"id":"-EqvTSjZZIUE"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"dlCSHY5_Y0wb"},"source":["The dataset chosen for this experiment is the **ab_data.csv** dataset which is publicly available on [Kaggle](https://www.kaggle.com/datasets/abdelrahmanrezk7/ab-testing-e-commerce-website)  \n","\n","This dataset consists of 2,94,478 records. Each record is made up of 5 fields.\n","\n","**For example**, Each record consists of 'user_id', 'timestamp', 'group', 'landing_page' and 'converted'.\n","\n","* **user_id:** A unique identifier assigned to each user participating in the experiment.\n","\n","* **timestamp:** The timestamp indicating the time at which the user interacted with the webpage or was exposed to the experimental condition.\n","\n","* **group:** The group to which the user was assigned, typically denoted as either 'control' or 'treatment'. This field helps categorize users into different experimental conditions.\n","\n","* **landing_page:** Specifies the type of landing page or webpage variant that the user was directed to upon interaction. It distinguishes between different versions of the webpage used in the experiment.\n","\n","* **converted:** A binary indicator representing whether the user performed the desired action or conversion after interacting with the webpage. It typically indicates whether the user made a purchase, signed up for a service, or completed any other desired action."]},{"cell_type":"markdown","metadata":{"id":"V3vgcWwOF2cK"},"source":["## Problem Statement"]},{"cell_type":"markdown","metadata":{"id":"GYdLgvhhZtwA"},"source":["The biggest e-commerce company called FaceZonGoogAppFlix approached to a data science consulting firm as a new client!\n","\n","They have a potential new webpage designed with the intention to increase their current conversion rates of 12% by 0.35% or more. With such an ambiguous task, they have full trust in the data science consulting firm to give them a recommendation whether to implement the new web page or keep the old webpage. Unfortunately they haven't built up a data science capability in their company, but they've used an external software called 'A/B Tester' for 23 days and then come back to the data science consulting firm with a dataset. Under this requirement scenario, what the data science consulting firm will do?"]},{"cell_type":"code","metadata":{"id":"qwmmvQnv3mLM","cellView":"form"},"source":["# @title Download the Dataset\n","! wget -q https://cdn.exec.talentsprint.com/static/cds/content/ab_data.csv\n","! wget -q https://cdn.exec.talentsprint.com/static/cds/content/countries.csv\n","print(\"The datset was downloaded\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part I - Probability**"],"metadata":{"id":"zkN12h1bjv2z"}},{"cell_type":"markdown","metadata":{"id":"epVoy2b_Z05e"},"source":["#### Import required packages"]},{"cell_type":"code","metadata":{"id":"sBpCF4GlBPFL"},"source":["import pandas as pd\n","import numpy as np\n","import scipy.stats as ss\n","import statsmodels.api as sm\n","import math as mt\n","import itertools\n","import random\n","from patsy import dmatrices\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","import matplotlib.pyplot as plt\n","from scipy.stats import norm\n","%matplotlib inline\n","#We are setting the seed to assure that each of your Additional Notebook peer group members gets the same answers\n","random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YmOJDVdp9PYo"},"source":["#### Load the dataset"]},{"cell_type":"code","metadata":{"id":"6DrVCIg54LZp"},"source":["# YOUR CODE HERE\n","# a. Read in the dataset and take a look at the top few rows here:\n","data = pd.read_csv('/content/ab_data.csv') # 2,94,478 rows and 5 columns\n","df = data.copy()\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# b. Use the below cell to find the number of rows in the dataset.\n","df.shape"],"metadata":{"id":"B9Jg6Z0KML6r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"li5KS0i3pQqq"},"source":["## Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"Edt4IHsO4lua"},"source":["### Step 1: Data Cleaning\n","\n","* Check the number of unique users in the dataset\n","\n","* Check the proportion of users converted.\n","  \n","    **Hint:** query(), count()\n","* Estimate how many times the new_page and treatment don't line up. Also estimate how many times the old_page and control do not match.\n","\n","* Display the total no. of non-line up pages\n","\n","* Check if any of the rows have missing values?\n","\n","#### **Treatment Group & Control Group**\n","* **Treatment Group (New Webpage):**\n","Users in this group will be exposed to the new webpage design.\n","The effectiveness of the new webpage design will be measured by comparing the conversion rates of users (who actually make purchase of the company's products after visiting this new webpage) in this group to those in the control groups.\n","* **Control Group 1 (Placebo):**\n","Users in this group will be presented with an identical-looking webpage that serves as a placebo.\n","This group represents the baseline scenario where users are exposed to the current webpage design without any changes.\n","It means that in Control Group 1, users will see a webpage that looks exactly like the current one (new one) but doesn't have any actual changes. This group helps us understand how users typically behave on the current webpage without any alterations. It's like giving users a fake version of the webpage to see how they respond, so we can compare their behavior to those users who see the real changes in the actual new webpage.\n","* **Control Group 2 (Old Webpage or Existing Treatment):**\n","Users in this group will be shown a webpage that is already in use and has demonstrated effectiveness in terms of conversion rates. It means that users in Control Group 2 will see the same old webpage that is currently being used. This webpage has been proven to be effective in terms of converting visitors into purchasers (or customers) in the past.\n","\n","-- This group serves as a benchmark to evaluate whether the new webpage design outperforms the existing treatment.\n","\n","-- This group (Control Group 2) acts as a standard for comparison to see if the new webpage design performs better than the current one. We will use the conversion rates observed in Control Group 2 to assess whether the changes made in the new webpage design lead to better results or not."]},{"cell_type":"code","metadata":{"id":"bGXvWzHWZTUg"},"source":["# c. The number of unique users in the dataset.\n","df.user_id.nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9Vj8ld6ZaIg"},"source":["df.query('converted == 1')['converted'].count() / df.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-3Wh2RL4Z0t"},"source":["# identify treatment does not match with new_page\n","N1 = df.query('group == \"treatment\" and landing_page != \"new_page\"').count()[0]\n","N1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIFju1AqFd1t"},"source":["# identify control does not match with old_page\n","N2 = df.query('group != \"treatment\" and landing_page == \"new_page\"').count()[0]\n","N2"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Total no. of non-line up\n","N = N1 + N2\n","N"],"metadata":{"id":"v15b7XvZPSF6"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnAgcxCHGywv"},"source":["# Check for any missing values\n","df.isnull().sum().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gqq4CX4gG3zU"},"source":["# Check datatype of each column\n","df.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3PVM_RBKbjZ6"},"source":["### Step 2: Identify the not aligned rows\n","\n","<u>**Part-2a:**</u>\n","\n","With the above dataset (achieved in Task-1) the requirement is to first identify the rows in that dataset where the treatment group is aligned with the new_page and where the control group is aligned with the old_page.\n","\n","**Hint:** It creates a new DataFrame containing these filtered rows.\n","**('group == \"treatment\" and landing_page == \"new_page\"')**\n","\n","<u>**Part-2b:**</u>\n","\n","Now, with the help of the new dataset (achieved in Task-2), we need to identify the misaligned rows in the dataset (achieved in Task-1) where treatment is not aligned with new_page or control is not aligned with old_page\n","\n","This can be done by checking the values 'treatment' and 'control' under the 'group' column to ensure they do not correspond with the values 'new_page' and 'old_page' under the 'landing_page' column, respectively.\n","\n","For the rows where treatment is not aligned with new_page or control is not aligned with old_page, we cannot be sure if this row truly received the new or old page. Write your code to provide how we should handle these rows."]},{"cell_type":"code","metadata":{"id":"ibXbIHHPQXZL"},"source":["# Part-2a\n","# create a new dataset that meets the specifications:\n","# treatment is aligned with new_page or control is aligned with old_page\n","df2 = df.iloc[df.query('group == \"treatment\" and landing_page == \"new_page\"').index.values]\n","\n","df3 = df.iloc[df.query('group == \"control\" and landing_page == \"old_page\"').index.values]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VcejgyYbnhf"},"source":["df2 = pd.concat([df2, df3], ignore_index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpE9zOpnTn8n"},"source":["df2.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Part-2b\n","# Identify misaligned rows where treatment is not aligned with new_page or control is not aligned with old_page\n","df_misaligned = df[~df.index.isin(df2.index)]\n","df_misaligned"],"metadata":{"id":"WXxs_UpwqhXr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Double Check all of the correct rows were removed - this should be 0\n","df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"],"metadata":{"id":"NJyZYPBlTlIl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xc3UOT74MM3O"},"source":["### Step-3:Using the above new dataset, Check the following points.\n","\n","* How many unique user_ids are in the new dataset created above in Task-2?\n","\n","* There is one user_id repeated in this dataset.  (Here we need to show only the user_id)\n","\n","* What is the row information for the repeat user_id? (Here, we need to show the complete row including 'user_id', 'timestamp', 'group', 'landing_page' and\t'converted')\n","\n","* Remove one of the rows with a duplicate user_id, but keep your dataframe name as same."]},{"cell_type":"code","metadata":{"id":"9dn_ljWWAcNM"},"source":["df2.user_id.nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["duplicated_user_ids = df2[df2.duplicated(['user_id'])]['user_id'].unique()\n","print(\"Duplicated user_id:\", duplicated_user_ids)"],"metadata":{"id":"a5feaxXUbnIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.query('user_id == 773192')"],"metadata":{"id":"-7MFS8RWbW7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.drop(1899, inplace=True)\n","df2.head()"],"metadata":{"id":"558Lw12Acf8i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrPzlHc4-zIR"},"source":["## Finding Probabilities"]},{"cell_type":"markdown","metadata":{"id":"qFgtC_jCpJL1"},"source":["### Step 4: After removing the duplicated user_id, answer the following:"]},{"cell_type":"markdown","metadata":{"id":"5QQ2WUQX9XYy"},"source":["##### Exercise 1: What is the probability of an individual converting regardless of the page they receive?"]},{"cell_type":"code","metadata":{"id":"zcRjzr9YRo72"},"source":["# YOUR CODE HERE\n","df2.converted.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzzEnMv25vGn"},"source":["##### Exercise 2: Given that an individual was in the control group, what is the probability they converted?"]},{"cell_type":"code","metadata":{"id":"NWHrrw2BJrb7"},"source":["# YOUR CODE HERE\n","control_df = df2.query('group == \"control\"')\n","control_convert = df2.query('group == \"control\"').converted.mean()\n","control_convert"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OFNIQ4dj59Ep"},"source":["##### Exercise 3: Given that an individual was in the treatment group, what is the probability they converted?"]},{"cell_type":"code","metadata":{"id":"0ZDWxb_JRtBl"},"source":["# YOUR CODE HERE\n","treatment_df = df2.query('group == \"treatment\"')\n","treatment_convert = df2.query('group == \"treatment\"').converted.mean()\n","treatment_convert"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LBreBsQ7Vqi0"},"source":["\n","##### Exercise 4: What is the probability that an individual received the new page?"]},{"cell_type":"code","metadata":{"id":"RFUmNVsCTR_t"},"source":["# YOUR CODE HERE\n","\n","P_receiving_new_page = df2.query('landing_page == \"new_page\"').count()[0] / df2.shape[0]\n","print(\"Probability of receiving new_page:\", P_receiving_new_page)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lDMFaGnT8NsJ"},"source":["# What is the probability that an individual received the old page?\n","P_receiving_old_page = 1 - P_receiving_new_page\n","print(\"Probability of receiving old_page:\", P_receiving_old_page)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9YKbXa-R8dCO"},"source":["obs_mean = treatment_convert - control_convert\n","obs_mean"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part II - A regression approach**"],"metadata":{"id":"RpkRfuUjbdlG"}},{"cell_type":"markdown","source":["1. In this final part, you will see that the result you acheived in the previous A/B test can also be acheived by performing regression.\n","\n","\n","**a.** Since each row is either a conversion or no conversion, what type of regression should you be performing in this case?\n","\n","Since we only need to yield two different output values that are categorical. We can perform a Logistic Regression model to compare two dummy variables rather than quantitative.\n","\n","**b.** The goal is to use statsmodels to fit the regression model you specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives.\n","* However, you first need to create a column for the intercept, and create a dummy variable column for which page each user received.\n","* Add an intercept column, as well as an ab_page column, which is **1** when an individual receives the treatment and **0** if control."],"metadata":{"id":"dqtsAk3kbrWJ"}},{"cell_type":"code","source":["df2['intercept'] = 1"],"metadata":{"id":"qf5kNtbac0RF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2['ab_page'] = pd.get_dummies(df2.group)['treatment']\n","df2.head()"],"metadata":{"id":"NQ88plzYc4LX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**c.** Use statsmodels to import your regression model. Instantiate the model, and fit the model using the two columns you created in part **b.** to predict whether or not an individual converts."],"metadata":{"id":"KN8RTrihc_20"}},{"cell_type":"code","source":["# Convert 'converted' column to numeric\n","df2['converted'] = pd.to_numeric(df2['converted'])\n","\n","# As 'intercept' column is binary indicator and it is of numeric type\n","df2['intercept'] = pd.to_numeric(df2['intercept'])\n","\n","# Convert 'ab_page' column to binary numeric values (0 and 1)\n","df2['ab_page'] = df2['ab_page'].astype(int)\n","\n","# Fit the logistic regression model\n","ls = sm.Logit(df2['converted'], df2[['intercept', 'ab_page']])\n","result = ls.fit()"],"metadata":{"id":"jVPEt0v4dQCl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**d.** Provide the summary of your model below, and use it as necessary to answer the following questions."],"metadata":{"id":"UutYzVE_gbDF"}},{"cell_type":"code","source":["result.summary()"],"metadata":{"id":"9CTVorbbghG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfc = pd.read_csv('/content/countries.csv')\n","dfc.head()"],"metadata":{"id":"gRAXtnWfkG0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2 = df2.merge(dfc, on='user_id')\n","df2.head()"],"metadata":{"id":"R-BxKc86kpeU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2[['CA', 'UK']] = pd.get_dummies(df2.country)[['CA', 'UK']]\n","df2.head()"],"metadata":{"id":"0ijVp0jwkuCa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We select CA and UK and drop the US column to make the matrice full rank."],"metadata":{"id":"g9auJrJBkyO5"}},{"cell_type":"code","source":["df2['new_page'] = pd.get_dummies(df2.landing_page)['new_page']\n","df2.head()"],"metadata":{"id":"2Hea_fM6k1nx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert 'new_page' column to binary numeric values (0 and 1)\n","df2['new_page'] = df2['new_page'].astype(int)\n","\n","# Convert 'UK' column to binary numeric values (0 and 1)\n","df2['UK'] = df2['UK'].astype(int)\n","\n","# Convert 'CA' column to binary numeric values (0 and 1)\n","df2['CA'] = df2['CA'].astype(int)"],"metadata":{"id":"4xhByUSimBei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a logistic regression model with baselines as US and old_page\n","logit = sm.Logit(df2.converted, df2[['intercept', 'new_page', 'CA', 'UK']])\n","result = logit.fit()\n","result.summary()"],"metadata":{"id":"dFM7q2Edk5pK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["-- The predicted difference in the conversion of a page in CA as compared to the US holding other variables constant : **-0.0407**\n","\n","-- The predicted difference in the conversion of a page in UK as compared to the US holding other variables constant : **0.0099**\n","\n","-- For every one unit increase new page, we predict the conversion of a page to decrease by **0.0150** holding all other variables constant.\n","\n","-- The predicted converted page if the user views the old page in the US. = **-1.9893**"],"metadata":{"id":"3wbP6bNfmkHL"}},{"cell_type":"markdown","source":["Let's calculate **Variance Inflation Factor (VIF)** value in order to determine whether we have multicollinearity in our model."],"metadata":{"id":"cbkWXRGnnn1y"}},{"cell_type":"code","source":["y, X = dmatrices('converted ~ new_page + CA + UK', df2, return_type='dataframe')\n","\n","vif = pd.DataFrame()\n","vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n","vif[\"features\"] = X.columns\n","\n","vif"],"metadata":{"id":"AI98sUPgnqsS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As a result, features' values are not larger than 10 that is, we don't have multicallinearity in our model."],"metadata":{"id":"B-sTYBEIoHU5"}},{"cell_type":"markdown","source":["**h.** Though you have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion. Create the necessary additional columns, and fit the new model.\n","\n","Provide the summary results, and your conclusions based on the results."],"metadata":{"id":"XZIIW8agoP56"}},{"cell_type":"code","source":["df2['CA_new'] = df2['new_page'] * df2['CA']\n","df2['UK_new'] = df2['new_page'] * df2['UK']"],"metadata":{"id":"3hjRbrzVoWJK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a second logistic regression model with baselines as US and old_page\n","logit = sm.Logit(df2.converted, df2[['intercept', 'new_page', 'CA_new', 'UK_new', 'CA', 'UK']])\n","result = logit.fit()\n","result.summary()"],"metadata":{"id":"5sZFbA1PoaO5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Based on the results, only the intercept is statically significant. The coefficient of intereaction variables namely CA_new and UK_new are slightly different from the coefficient of new_page itself. I think adding a higher order term between page and country is useful in predicting the conversion of page.\n","\n","-- For every one unit increase in the conversion for new page from UK, the predicted increase in convertion is by **0.0315.**\n","\n","-- For every one unit increase in the conversion for new page from CA, the predicted decrease in convertion is by **-0.0468.**\n","\n","-- The predicted difference between the conversion of pages viewed from CA and from US holding all other variables constant is **-0.0175.**\n","\n","-- The predicted difference between the conversion of pages viewed from UK and from US holding all other variables constant is **-0.0057.**"],"metadata":{"id":"RVFMONjeohlp"}}]}