{"cells":[{"cell_type":"markdown","metadata":{"id":"zZbO1TP3GWLl"},"source":["# Advanced Certification Program in Computational Data Science\n","## A program by IISc and TalentSprint\n","### Additional Notebook (ungraded): Tuning hyperparameters using Optuna"]},{"cell_type":"markdown","source":["# Introduction\n","\n","Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning. It features an imperative, define-by-run style user API.\n","\n","Optuna has modern functionalities as follows:\n","\n","- Lightweight, versatile, and platform agnostic architecture\n","  - Handle a wide variety of tasks with a simple installation that has few requirements.\n","- Pythonic search spaces\n","  - Define search spaces using familiar Python syntax including conditionals and loops.\n","- Efficient optimization algorithms\n","  - Adopt state-of-the-art algorithms for sampling hyperparameters and efficiently pruning unpromising trials.\n","- Easy parallelization\n","  - Scale studies to tens or hundreds or workers with little or no changes to the code.\n","- Quick visualization\n","  - Inspect optimization histories from a variety of plotting functions."],"metadata":{"id":"jPNABFsVcDc5"}},{"cell_type":"markdown","metadata":{"id":"7cLCrniZYsdW"},"source":["# Tuning Hyperparameters using Optuna\n","\n","- Install Optuna\n","- Write a training algorithm that involves hyperparameters\n","  - Read train/valid data\n","  - Define and train the model\n","  - Evaluate model\n","- Use Optuna to tune the hyperparameters (hyperparameter optimization)\n","- Visualize the hyperparameter optimization"]},{"cell_type":"markdown","metadata":{"id":"a1L5pkPtYsdZ"},"source":["## Install `optuna`\n","\n","Optuna can be installed via `pip` or `conda`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms_n9vi8Ysda"},"outputs":[],"source":["!pip install --quiet optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OO2KVUheYsdb"},"outputs":[],"source":["import optuna\n","\n","optuna.__version__"]},{"cell_type":"markdown","metadata":{"id":"gwQ6ZviGYsdb"},"source":["## Optimize Hyperparameters\n","\n","### Define a simple scikit-learn model\n","\n","We start with a simple random forest model to classify flowers in the Iris dataset.\n","- Define a function called `objective` that encapsulates the whole training process and outputs the accuracy of the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNrBYywkYsdc"},"outputs":[],"source":["import sklearn.datasets\n","import sklearn.ensemble\n","import sklearn.model_selection\n","\n","def objective():\n","    iris = sklearn.datasets.load_iris()  # Prepare the data.\n","\n","    clf = sklearn.ensemble.RandomForestClassifier(\n","        n_estimators=5, max_depth=3)  # Define the model.\n","\n","    return sklearn.model_selection.cross_val_score(\n","        clf, iris.data, iris.target, n_jobs=-1, cv=3).mean()  # Train and evaluate the model.\n","\n","print('Accuracy: {}'.format(objective()))"]},{"cell_type":"markdown","metadata":{"id":"RXPWrAGRYsdd"},"source":["### Optimize hyperparameters of the model\n","\n","The hyperparameters of the above algorithm are `n_estimators` and `max_depth`, for which we can try different values to see if the model accuracy can be improved. The `objective` function is modified to accept a trial object. This trial has several methods for sampling hyperparameters. We create a study to run the hyperparameter optimization and finally arrive at the most optimal hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3rqR2VpCYsdf"},"outputs":[],"source":["import optuna\n","\n","def objective(trial):\n","    iris = sklearn.datasets.load_iris()\n","\n","    n_estimators = trial.suggest_int('n_estimators', 2, 20)\n","    max_depth = int(trial.suggest_float('max_depth', 1, 32, log=True))\n","\n","    clf = sklearn.ensemble.RandomForestClassifier(\n","        n_estimators=n_estimators, max_depth=max_depth)\n","\n","    return sklearn.model_selection.cross_val_score(\n","        clf, iris.data, iris.target, n_jobs=-1, cv=3).mean()\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=100)\n","\n","trial = study.best_trial\n","\n","print('Accuracy: {}'.format(trial.value))\n","print(\"Best hyperparameters: {}\".format(trial.params))"]},{"cell_type":"markdown","metadata":{"id":"w5mWAfTgYsdh"},"source":["### Plotting the study\n","\n","Plotting the optimization history of the study."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ald7USb0Ysdi"},"outputs":[],"source":["optuna.visualization.plot_optimization_history(study)"]},{"cell_type":"markdown","metadata":{"id":"l0OBal_oYsdi"},"source":["Plotting the accuracies for each hyperparameter for each trial."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tl0DwaCrYsdj"},"outputs":[],"source":["optuna.visualization.plot_slice(study)"]},{"cell_type":"markdown","metadata":{"id":"3-nFVTb7Ysdj"},"source":["Plotting the accuracy surface for the hyperparameters involved in the random forest model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BCnJRIaYYsdj"},"outputs":[],"source":["optuna.visualization.plot_contour(study, params=['n_estimators', 'max_depth'])"]},{"cell_type":"markdown","source":["# Reference Reading:\n","\n","[Optuna - hyperparameter optimization framework](https://cdn.iisc.talentsprint.com/CDS/Assignments/Module2/Addl_NB_Tuning_hyperparameters_using_Optuna_Reference%20Reading%20Optuna%20a%20flexible%20efficient.pdf)\n","\n","[Optuna examples](https://github.com/optuna/optuna-examples/)\n","\n","[Optuna vs Hyperopt](https://neptune.ai/blog/optuna-vs-hyperopt)\n","\n","\n"],"metadata":{"id":"XN-TIGRbhVTN"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}