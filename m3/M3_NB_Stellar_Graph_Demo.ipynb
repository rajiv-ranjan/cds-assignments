{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s5Ud8CYiyLhl"},"source":["# Advanced Certification Program in Computational Data Science\n","## A program by IISc and TalentSprint\n","### Demo Notebook: Stellar Graph Library"]},{"cell_type":"markdown","metadata":{"id":"92j0Gh6xyanz"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"4Im-YrkmyaNv"},"source":["At the end of the experiment, you will be able to\n","\n","- understand the stellargraph library applications\n","- understand various tools and functional API of stellargraph library"]},{"cell_type":"markdown","metadata":{"id":"XWEJ3rRTyaH5"},"source":["### Introduction"]},{"cell_type":"markdown","metadata":{"id":"vDAt6XvEyd3i"},"source":["The StellarGraph library offers state-of-the-art algorithms for graph machine learning, making it easy to discover patterns and answer questions about graph-structured data. It can solve many machine learning tasks:\n","\n","* Representation learning for nodes and edges, to be used for visualisation and various downstream machine learning tasks;\n","\n","* Classification and attribute inference of nodes or edges;\n","\n","* Classification of whole graphs;\n","\n","* Link prediction;\n","\n","* Interpretation of node classification\n","\n","Graph-structured data represent entities as nodes (or vertices) and relationships between them as edges (or links), and can include data associated with either as attributes. StellarGraph supports analysis of many kinds of graphs:\n","\n","* homogeneous (with nodes and links of one type),\n","\n","* heterogeneous (with more than one type of nodes and/or links)\n","\n","* knowledge graphs (extreme heterogeneous graphs with thousands of types of edges)\n","\n","* graphs with or without data associated with nodes\n","\n","* graphs with edge weights\n","\n","StellarGraph is built on `TensorFlow` and its `Keras high-level API`, as well as `Pandas` and `NumPy`. It is thus user-friendly, modular and extensible. It interoperates smoothly with code that builds on these, such as the standard Keras layers and `scikit-learn`, so it is easy to augment the core graph machine learning algorithms provided by StellarGraph. It is thus also easy to install with `pip` or Anaconda."]},{"cell_type":"markdown","metadata":{"id":"b9uWmqNH5YfK"},"source":["One of the most exciting features of StellarGraph 1.0 is a new graph data structure — built using NumPy and Pandas — that results in significantly lower memory usage and faster construction times."]},{"cell_type":"markdown","metadata":{"id":"6xCo3XIc5aOp"},"source":["### Faster machine learning on larger graphs with NumPy and Pandas\n"]},{"cell_type":"markdown","metadata":{"id":"xaCcHKfw5BuM"},"source":["The core abstraction in the library is the [StellarGraph class](https://stellargraph.readthedocs.io/en/stable/api.html#stellargraph.StellarGraph), which is a graph data structure that manages all the information about the graph or graphs being used for machine learning.\n","\n","Previous versions of the StellarGraph class were backed by [NetworkX](https://networkx.org/), which allowed for quick and effective development of many graph machine learning algorithms because of its convenient and flexible API, built using nested dictionaries. However, this flexibility meant it wasn’t optimised for graph machine learning: NetworkX has different trade-offs than those best for machine learning, the most notable being the amount of memory required to store a graph.\n","\n","So, over the releases leading up to 1.0, the NetworkX-backed graph data structure was replaced with a new one built using NumPy and Pandas.\n","\n","#### How does it work?\n","\n","There are three key parts to the new StellarGraph class:\n","\n","- Efficient storage of edges\n","- Keeping node features available for quick indexing\n","- Support for arbitrary node IDs.\n","\n","**Efficient storage of edges**\n","\n","The new StellarGraph class stores most of its data using NumPy arrays.\n","\n","![Image](https://www.kdnuggets.com/wp-content/uploads/stellargraph-numpy-pandas-2.png)\n","\n","$\\text{Figure 1: A NumPy array can consist of a single chunk of memory with values stored inline}$\n","\n","*A Python list stores pointers to other Python objects, and each of these has extra metadata overhead, dramatically increasing the cost over NumPy*.\n","\n","The edges of the graph are conceptually pairs of a source node ID and a target node ID, representing the connection between the two nodes. In the new StellarGraph class, the edges are stored as NumPy arrays containing the source and targets in a [“structure of arrays”](https://en.wikipedia.org/wiki/AoS_and_SoA) style.\n","\n","#### Keeping node features available for quick indexing\n","\n","NumPy arrays are also used for node features. StellarGraph is optimised for machine learning, which typically means working with vectors of “features”, or lists of numbers that encode information about each entity.\n"]},{"cell_type":"markdown","metadata":{"id":"5ErV0R4M0a3D"},"source":["### Getting Started"]},{"cell_type":"code","source":["!pip install chardet"],"metadata":{"id":"6Lz-lY1FIrCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fv2itA1kx2Wt"},"source":["# Install StellarGraph\n","#!pip -q install stellargraph"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install git+https://github.com/VenkateshwaranB/stellargraph.git"],"metadata":{"id":"x1iflRx1Jqm2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWcAu50y2SRj"},"source":["# verify that we're using the correct version of StellarGraph for this notebook\n","import stellargraph as sg\n","\n","try:\n","    sg.utils.validate_notebook_version(\"1.2.1\")\n","except AttributeError:\n","    raise ValueError(\n","        f\"This notebook requires StellarGraph version 1.2.1, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n","    ) from None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkFaExAV3iI8"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqfwnEwoLFuk"},"source":["### Core"]},{"cell_type":"markdown","metadata":{"id":"Fx22KKpJEgQ-"},"source":["To create a StellarGraph object, at a minimum pass the edges as a Pandas DataFrame. Each row of the edges DataFrame represents an edge, where the index is the ID of the edge, and the source and target columns store the node ID of the source and target nodes.\n","\n","For example, suppose we’re modelling a graph that’s a square with a diagonal:\n","\n","```\n","a -- b\n","| \\  |\n","|  \\ |\n","d -- c\n","```\n","\n","The DataFrame might look like:\n","\n"]},{"cell_type":"code","metadata":{"id":"Ryp20sA1EguU"},"source":["edges = pd.DataFrame(\n","    {\"source\": [\"a\", \"b\", \"c\", \"d\", \"a\"], \"target\": [\"b\", \"c\", \"d\", \"a\", \"c\"]}\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QPk0iCKxFPDJ"},"source":["If this data represents an undirected graph (the ordering of each edge source/target doesn’t matter):"]},{"cell_type":"code","metadata":{"id":"CPTR8eT-FLps"},"source":["Gs = sg.StellarGraph(edges=edges)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fLr4hZDFFxC-"},"source":["If this data represents a directed graph (the ordering does matter):"]},{"cell_type":"code","metadata":{"id":"Nsr76oP0FR2n"},"source":["Gs = sg.StellarDiGraph(edges=edges)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7eldgHMCF-Vc"},"source":["One can also pass information about nodes, as either:\n","\n","* a `IndexedArray`\n","\n","* a NumPy array, if the node IDs are 0, 1, 2, …\n","\n","* a Pandas DataFrame\n","\n","Each row of the nodes frame (first dimension of the NumPy array) represents a node in the graph, where the index is the ID of the node."]},{"cell_type":"code","metadata":{"id":"NdMUK_1YF4CW"},"source":["nodes = sg.IndexedArray(index=[\"a\", \"b\", \"c\", \"d\"])\n","Gs = sg.StellarGraph(nodes, edges)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wOzFKsnWGNZi"},"source":["Numeric node features are taken as any columns of the nodes DataFrame. For example, if the graph above has two features `x` and `y` associated with each node:"]},{"cell_type":"code","metadata":{"id":"yaBVpgTbGFjm"},"source":["# As a IndexedArray (no column names):\n","feature_array = np.array([[-1, 0.4], [2, 0.1], [-3, 0.9], [4, 0]])\n","nodes = sg.IndexedArray(feature_array, index=[\"a\", \"b\", \"c\", \"d\"])\n","\n","# As a Pandas DataFrame:\n","nodes = pd.DataFrame(\n","    {\"x\": [-1, 2, -3, 4], \"y\": [0.4, 0.1, 0.9, 0]}, index=[\"a\", \"b\", \"c\", \"d\"]\n",")\n","\n","# As a NumPy array:\n","# Note, edges must change to using 0, 1, 2, 3 (instead of a, b, c, d)\n","nodes = feature_array"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r2_wj6P1Hfli"},"source":["Construction directly from a `IndexedArray or NumPy` array will have the least overhead, but construction from Pandas allows for convenient data transformation.\n","\n","Edge weights are taken as the optional weight column of the edges DataFrame:"]},{"cell_type":"code","metadata":{"id":"wOzEpyM5GaCZ"},"source":["edges = pd.DataFrame({\n","    \"source\": [\"a\", \"b\", \"c\", \"d\", \"a\"],\n","    \"target\": [\"b\", \"c\", \"d\", \"a\", \"c\"],\n","    \"weight\": [10, 0.5, 1, 3, 13]\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pFYAU3sqJvd8"},"source":["Numeric edge features are taken by any columns that do not have a special meaning (that is, excluding source, target and the optional weight or edge_type_column columns). For example, if the graph has weighted edges with two features a and b associated with each node:"]},{"cell_type":"code","metadata":{"id":"T1LzstqSHlAx"},"source":["edges = pd.DataFrame({\n","    \"source\": [\"a\", \"b\", \"c\", \"d\", \"a\"],\n","    \"target\": [\"b\", \"c\", \"d\", \"a\", \"c\"],\n","    \"weight\": [10, 0.5, 1, 3, 13],\n","    \"a\": [-1, 2, -3, 4, -5],\n","    \"b\": [0.4, 0.1, 0.9, 0, 0.9],\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3FOyinCKYR9"},"source":["### Edge Splitter\n"]},{"cell_type":"markdown","metadata":{"id":"F3OArNDRNIU_"},"source":["```\n","class stellargraph.data.EdgeSplitter(g, g_master=None)\n","```\n","\n","Class for generating training and test data for `link prediction` in graphs.\n","\n","Parameters:\n","- `g (StellarGraph)` – The graph to sample edges from.\n","\n","- `g_master (StellarGraph)` – The graph representing the original dataset and a superset of the graph g. If it is not None, then when positive and negative edges are sampled, care is taken to make sure that a true positive edge is not sampled as a negative edge.\n","\n","```\n","train_test_split(p=0.5, method='global', probs=None, keep_connected=False, edge_label=None, edge_attribute_label=None, edge_attribute_threshold=None, attribute_is_datetime=None, seed=None)\n","```\n","\n","Returns:\n","\n","The reduced graph (positive edges removed) and the edge data as 2 numpy arrays, the first array of dimensionality N × 2 (where N is the number of edges) holding the node ids for the edges and the second of dimensionality N × 1 holding the edge labels, 0 for negative and 1 for positive examples. The graph matches the input graph passed to the EdgeSplitter constructor: the returned graph is a `StellarGraph` instance if the input graph was one."]},{"cell_type":"markdown","metadata":{"id":"DAMYeUmVYO2d"},"source":["### Layers and models\n","\n","The layer package contains implementations of popular neural network layers for graph ML as Keras layers."]},{"cell_type":"markdown","metadata":{"id":"9ZhZy9rSZUHD"},"source":["#### GCN\n","\n","```\n","class stellargraph.layer.GCN(layer_sizes, generator, bias=True, dropout=0.0, activations=None, kernel_initializer='glorot_uniform', kernel_regularizer=None, kernel_constraint=None, bias_initializer='zeros', bias_regularizer=None, bias_constraint=None, squeeze_output_batch=True)\n","```\n","\n","A stack of Graph Convolutional layers that implement a graph convolution network model as in https://arxiv.org/abs/1609.02907\n","\n","The model minimally requires specification of the layer sizes as a list of int corresponding to the feature dimensions for each hidden layer, activation functions for each hidden layers, and a generator object.\n","\n","To use this class as a Keras model, the features and preprocessed adjacency matrix should be supplied using:\n","\n","- the `FullBatchNodeGenerator` class for node inference\n","\n","- the `ClusterNodeGenerator` class for scalable/inductive node inference using the Cluster-GCN training procedure (https://arxiv.org/abs/1905.07953)\n","\n","- the `FullBatchLinkGenerator` class for link inference\n","\n","To have the appropriate preprocessing the generator object should be instantiated with the `method='gcn'` argument.\n","\n","\n","Example\n","\n","Creating a GCN node classification model from an existing StellarGraph object G:\n","```\n","generator = FullBatchNodeGenerator(G, method=\"gcn\")\n","gcn = GCN(\n","        layer_sizes=[32, 4],\n","        activations=[\"elu\",\"softmax\"],\n","        generator=generator,\n","        dropout=0.5\n","    )\n","x_inp, predictions = gcn.in_out_tensors()\n","```"]},{"cell_type":"markdown","metadata":{"id":"0ist6CcdaDsy"},"source":["Examples using GCN:\n","\n","- node classification\n","\n","- node classification trained with Cluster-GCN\n","\n","- semi-supervised node classification\n","\n","- link prediction\n","\n","- interpreting GCN predictions: dense, sparse\n","\n","- ensemble model for node classification\n","\n","- comparison of link prediction algorithms\n","\n","Appropriate data generators: `FullBatchNodeGenerator`, `FullBatchLinkGenerator`, `ClusterNodeGenerator`.\n","\n","Related models:\n","\n","Other full-batch models: see the documentation of [FullBatchNodeGenerator](https://stellargraph.readthedocs.io/en/stable/api.html#stellargraph.mapper.FullBatchNodeGenerator) for a full list\n","\n","`GCNSupervisedGraphClassification` for graph classification by pooling the output of `GCN`\n","\n","`GCN_LSTM` for `time-series` and sequence prediction, incorporating the graph structure via `GCN`\n","\n","Parameters:\n","- `layer_sizes (list of int)` – Output sizes of GCN layers in the stack.\n","\n","- `generator (FullBatchNodeGenerator)` – The generator instance.\n","\n","- `bias (bool)` – If True, a bias vector is learnt for each layer in the GCN model.\n","\n","- `dropout (float)` – Dropout rate applied to input features of each GCN layer.\n","\n","- `activations (list of str or func)` – Activations applied to each layer’s output; defaults to ['relu', ..., 'relu'].\n","\n","- `kernel_initializer (str or func, optional)` – The initialiser to use for the weights of each layer.\n","\n","- `kernel_regularizer (str or func, optional)` – The regulariser to use for the weights of each layer.\n","\n","- `kernel_constraint (str or func, optional)` – The constraint to use for the weights of each layer.\n","\n","- `bias_initializer (str or func, optional)` – The initialiser to use for the bias of each layer.\n","\n","- `bias_regularizer (str or func, optional)` – The regulariser to use for the bias of each layer.\n","\n","- `bias_constraint (str or func, optional)` – The constraint to use for the bias of each layer.\n","\n","- `squeeze_output_batch (bool, optional)` – if True, remove the batch dimension when the batch size is 1. If False, leave the batch dimension."]},{"cell_type":"markdown","metadata":{"id":"2frjviKnb23D"},"source":["#### GCN Supervised Graph Classification\n","\n","```\n","class stellargraph.layer.GCNSupervisedGraphClassification(layer_sizes, activations, generator, bias=True, dropout=0.0, pooling=None, pool_all_layers=False, kernel_initializer=None, kernel_regularizer=None, kernel_constraint=None, bias_initializer=None, bias_regularizer=None, bias_constraint=None)\n","```\n","\n","A stack of GraphConvolution layers together with a Keras GlobalAveragePooling1D layer (by default) that implement a supervised graph classification network using the GCN convolution operator (https://arxiv.org/abs/1609.02907).\n","\n","The model minimally requires specification of the GCN layer sizes as a list of int corresponding to the feature dimensions for each hidden layer, activation functions for each hidden layers, and a generator object.\n","\n","Examples\n","\n","Creating a graph classification model from a list of StellarGraph objects (graphs). We also add two fully connected dense layers using the last one for binary classification with softmax activation:\n","\n","```\n","generator = PaddedGraphGenerator(graphs)\n","model = GCNSupervisedGraphClassification(\n","                 layer_sizes=[32, 32],\n","                 activations=[\"elu\",\"elu\"],\n","                 generator=generator,\n","                 dropout=0.5\n","    )\n","x_inp, x_out = model.in_out_tensors()\n","predictions = Dense(units=8, activation='relu')(x_out)\n","predictions = Dense(units=2, activation='softmax')(predictions)\n","```\n","\n","Related models:\n","\n","- `DeepGraphCNN` for a specialisation using SortPooling\n","\n","- `GCN` for predictions for individual nodes or links"]},{"cell_type":"markdown","metadata":{"id":"6ki6dF5RcYfH"},"source":["#### Link Prediction\n","```\n","class stellargraph.layer.LinkEmbedding(*args, **kwargs)\n","```\n","\n","Defines an edge inference function that takes source, destination node embeddings (node features) as input, and returns a numeric vector of output_dim size.\n","\n","This class takes as input as either:\n","\n","- A list of two tensors of shape (N, M) being the embeddings for each of the nodes in the link, where N is the number of links, and M is the node embedding size.\n","\n","- A single tensor of shape (…, N, 2, M) where the axis second from last indexes the nodes in the link and N is the number of links and M the embedding size.\n","\n","Examples\n","\n","Consider two tensors containing the source and destination embeddings of size M:\n","\n","```\n","x_src = tf.constant(x_src, shape=(1, M), dtype=\"float32\")\n","x_dst = tf.constant(x_dst, shape=(1, M), dtype=\"float32\")\n","\n","li = LinkEmbedding(method=\"ip\", activation=\"sigmoid\")([x_src, x_dst])\n","```\n","\n","\n","Parameters:\n","- `axis (int)` – If a single tensor is supplied this is the axis that indexes the node embeddings so that the indices 0 and 1 give the node embeddings to be combined. This is ignored if two tensors are supplied as a list.\n","\n","- `activation (str)` – activation function applied to the output, one of “softmax”, “sigmoid”, etc., or any activation function supported by Keras, see https://keras.io/activations/ for more information.\n","\n","- `method (str)` –\n","\n","Name of the method of combining `(src,dst)` node features or embeddings into edge embeddings. One of:\n","\n","- `concat` – concatenation,\n","\n","- `ip` or `dot` – inner product, $ip(u,v)=sum_{i=1..d} * u_i∗v_i$,\n","\n","- `mul` or `hadamard` – element-wise multiplication, $h(u,v)_i=u_i∗v_i$,\n","\n","- `l1` – L1 operator, $l1(u,v)_i=|u_i−v_i|$,\n","\n","- `l2` – L2 operator, $l2(u,v)_i=(u_i−v_i)^2$,\n","\n","- `avg` – average, $avg(u,v)= \\frac{(u+v)}{2}$.\n","\n","For all methods except `ip` or `dot` a dense layer is applied on top of the combined edge embedding to transform to a vector of size `output_dim`."]}]}