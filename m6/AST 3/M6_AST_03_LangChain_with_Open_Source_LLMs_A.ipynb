{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Advanced Certification Program in Computational Data Science\n","## A Program by IISc and TalentSprint\n","### Assignment 3: Open Source LLMs with LangChain ðŸ¦œðŸ”—"],"metadata":{"id":"RMNv0S7qBl1Z"}},{"cell_type":"markdown","source":["## Learning Objectives\n","\n","At the end of the experiment, you will be able to:\n","\n","* use open source LLMs: **zephyr-7b-beta**, **Mistral-7B-Instruct-v0.2** through HuggingFaceHub with LangChain\n","* understand & use the concept of Prompt template, Memory and output parsers in LangChain\n"],"metadata":{"id":"R7nOHNxJqC2X"}},{"cell_type":"markdown","source":["### Setup Steps:"],"metadata":{"id":"rKQ0Fvl_jNqU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dG904xmKyK31"},"outputs":[],"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOc9lw37yK4A"},"outputs":[],"source":["#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"g9aMvFszyK4A"},"outputs":[],"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","\n","notebook= \"M5_AST_03_LangChain_with_Open_Source_LLMs_C\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","\n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n","              \"concepts\" : Concepts, \"record_id\" : submission_id,\n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_mentor_support\": Mentor_support}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://learn-iisc.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","\n","\n","def getAdditional():\n","  try:\n","    if not Additional:\n","      raise NameError\n","    else:\n","      return Additional\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","\n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","\n","# def getWalkthrough():\n","#   try:\n","#     if not Walkthrough:\n","#       raise NameError\n","#     else:\n","#       return Walkthrough\n","#   except NameError:\n","#     print (\"Please answer Walkthrough Question\")\n","#     return None\n","\n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","\n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError\n","    else:\n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","\n","def getId():\n","  try:\n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup\n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","else:\n","  print (\"Please complete Id and Password cells before running setup\")"]},{"cell_type":"markdown","source":["### Steps for Creating Hugging Face access tokens:\n","\n","* **Visit the Hugging Face Website:** Head to the Hugging Face website (https://huggingface.co/) to begin the account creation process.\n","\n","* **Click on â€œSign Upâ€:** Locate the â€œSign Upâ€ button on the top right corner of the homepage and click on it.\n","\n","* **Choose a Sign-Up Method:** Hugging Face offers multiple sign-up methods, including Google, GitHub, and email. Select your preferred method and follow the prompts to complete the registration.\n","\n","* **Verify Your Email (if applicable):** If you choose to sign up via email, verify your email address by clicking on the confirmation link sent to your inbox.\n","\n","* **Complete Your Profile:** Enhance your Hugging Face experience by completing your profile. Add a profile picture, a short bio, and any other details youâ€™d like to share with the community.\n","\n","* **Create Your Access Token:** Go to the link (https://huggingface.co/settings/tokens)\n","\n","* **Click on the option 'Access Tokens' from the left pane.**\n","\n","* **Then under the User Access Tokens, click on the button 'New token'.**\n","\n","* **Select Token type: Write.**\n","\n","* **Put your desired Token name.**\n","\n","* **Then at the bottom end, click on 'Create token'. The Hugging Face access token will be generated. Copy and paste the access token in your Google Colab Notebook.**"],"metadata":{"id":"Ax4k-S-fmCAn"}},{"cell_type":"markdown","source":["### Install required dependencies"],"metadata":{"id":"WeXRnNMfnFqF"}},{"cell_type":"code","source":["# Langchain\n","!pip -q install langchain\n","\n","# Library to communicate with HF hub\n","!pip -q install --upgrade huggingface_hub"],"metadata":{"id":"aKLiNSv6wTr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip -q install langchain_community"],"metadata":{"id":"UAsnCf4Z9e1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip -q install langchain_huggingface"],"metadata":{"id":"BrFlLJv3-_4N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Import required packages"],"metadata":{"id":"T0sgU1wiq7Hw"}},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","\n","from langchain_community.llms import HuggingFaceEndpoint\n","from langchain.prompts import PromptTemplate"],"metadata":{"id":"u0IydGx_q78h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Provide your HuggingFace api key/access token**"],"metadata":{"id":"dMBDqFT0kkgH"}},{"cell_type":"code","source":["# Enter your HuggingFace access token when prompted\n","\n","#Write code to Enter HUggingFace access token when prompted\n","#YOUR CODE HERE"],"metadata":{"id":"i9TSeu4cq1Jw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Exploring Open Source LLMs hosted on HuggingFace**\n","\n",">**I.** `HuggingFaceH4/zephyr-7b-beta`\n",">\n",">**II.** `mistralai/Mistral-7B-Instruct-v0.2`\n",">\n",">**III.** `LlaMa2`\n","\n","[LangChain link](https://python.langchain.com/docs/integrations/chat/huggingface) for using Hugging Face LLM's as chat models."],"metadata":{"id":"GgzDSiux-EuO"}},{"cell_type":"markdown","source":["### **I.** [**HuggingFaceH4/zephyr-7b-beta**](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)"],"metadata":{"id":"oVK3LSt6mzKa"}},{"cell_type":"code","source":["# Import HuggingFace model abstraction class from langchain\n","from langchain_huggingface import HuggingFaceEndpoint"],"metadata":{"id":"QudSou2y-T4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Instantiate an llm using HuggingFaceEndpoint with the repo ID \"HuggingFaceH4/zephyr-7b-beta\" and specified parameters for text generation\n","#YOUR CODE HERE"],"metadata":{"id":"jVRB1nztyTUm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke the llm with the prompt \"How to learn programming?\n","#YOUR CODE HERE"],"metadata":{"id":"qrneNiybIFl_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Prompt Template**\n","\n","Prompt templates are predefined recipes for generating prompts for language models.\n","\n","A template may include instructions, few-shot examples, and specific context and questions appropriate for a given task.\n","\n","LangChain provides tooling to create and work with prompt templates.\n","\n","To know more about Prompt template, refer [here](https://python.langchain.com/docs/modules/model_io/prompts/quick_start)."],"metadata":{"id":"F4N14UjkBaws"}},{"cell_type":"markdown","source":["#### **Example-1**"],"metadata":{"id":"-v-l3yx9hQs2"}},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","#Create a PromptTemplate that asks for a {adjective} joke about {content}, and format it to generate a funny joke about Trump\n","#YOUR CODE HERE"],"metadata":{"id":"NIjgIglFbjDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_huggingface import ChatHuggingFace\n","\n","#Instantiate a ChatHuggingFace model using the llm object\n","#YOUR CODE HERE"],"metadata":{"id":"iUOnAu5c_Hqw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Invoke chat_model with messages and print the content of the response\n"," #YOUR CODE HERE"],"metadata":{"id":"DjM9t0INbjLg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Example-2**"],"metadata":{"id":"ZPeo4FQBhL0l"}},{"cell_type":"code","source":["from langchain.schema import (\n","    HumanMessage,\n","    SystemMessage,\n",")"],"metadata":{"id":"bat0JTd7GrJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","prompt_template = PromptTemplate.from_template(\n","    \"Tell me {count} facts about {event_or_place}.\"\n",")\n","user_msg = prompt_template.format(count=5, event_or_place=\"Tajmahal\")\n","user_msg"],"metadata":{"id":"mQe8qxghewsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create a list of messages with a system message stating \"You're a knowledgeable historian\" and a human message containing user_msg\n","#YOUR CODE HERE"],"metadata":{"id":"GdGDCoQhmuDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_huggingface import ChatHuggingFace"],"metadata":{"id":"vCpfJTPCAqGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Initialize a ChatHuggingFace instance using the llm model\n","# YOUR CODE HERE"],"metadata":{"id":"9kg1GDWsCRbL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Access the model_id of the chat_model\n","#YOUR CODE HERE"],"metadata":{"id":"27Iyhp-5DJ5-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convert messages into a chat prompt\n","#YOUR CODE HERE"],"metadata":{"id":"9niBkmKIDMVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(chat_model._to_chat_prompt(messages))"],"metadata":{"id":"px6WPyxN2DYj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke the chat_model with a list of messages and print the content of the response\n","#YOUR CODE HERE"],"metadata":{"id":"ZduaUIkl-VpI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Example-3**\n","\n","The prompt to *chat models* is a list of chat messages.\n","\n","Each chat message is associated with content, and an additional parameter called `role`. For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role."],"metadata":{"id":"USL19U5MKapo"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate"],"metadata":{"id":"jsZWlMZEEcth"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"You are a helpful A {persona}.\"),\n","        (\"human\", \"Hello, how are you doing?\"),\n","        (\"ai\", \"I'm doing well, thanks!\"),\n","        (\"human\", \"{user_input}\"),\n","    ]\n",")"],"metadata":{"id":"TBLyJ-sFk8Hf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["persona = \"\"\"trustworthy friend\"\"\"\n","query= \"\"\"\n","I am not able to understand the concept taught in class. \\\n","Could you please suggest something? \\\n","I need your help. Give 5 points to work on.\n","\"\"\"\n","messages = chat_template.format_messages(persona = persona, user_input=query)"],"metadata":{"id":"1rr0S0bklaIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messages"],"metadata":{"id":"XoEgU1O5LlK7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#convert a list of messages into a chat prompt\n","#YOUR CODE HERE"],"metadata":{"id":"aP9IQ7q8mYu8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convert messages into a chat prompt and print the content of the chat prompt\n","#YOUR CODE HERE"],"metadata":{"id":"SOm5ZjnQ24jm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke chat_model with messages and print the content of the response\n","#YOUR CODE HERE"],"metadata":{"id":"tKH257JH_6qi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Practice :**\n","Create a prompt template that takes context and a question from the user and answers the question based on the given context.\n","\n","Hint: Keep the context in the system message and the question in the human message.\n","\n","**Context:** Meet Aryan Kapoor, a rising star in the entertainment industry whose talent knows no bounds. In 2023, Aryan captivated\n","audiences with his mesmerizing performance in the critically acclaimed film \"Echoes of Eternity,\" earning him the prestigious Best Actor award at the National Film Awards. His versatility shone brightly in 2024 when he showcased his vocal prowess as a playback singer in the chart-topping soundtrack of the blockbuster movie \"Infinite Horizon.\" The same year,  Aryan's captivating screen presence garnered him the coveted Filmfare Critics Award for Best Actor. As his star continued to\n","ascend, Aryan was honored with the International Icon of the Year award at the Global Entertainment Awards in 2025, recognizing his global impact and widespread admiration. With each role he undertakes, Aryan Kapoor cements his status as an unrivaled  talent in the world of cinema, leaving audiences eagerly anticipating his next masterpiece.\n","\n","**Question:** What awards did Aryan Kapoor win for his contributions to the entertainment industry, and in which years were they received?"],"metadata":{"id":"si6NaQVggzQq"}},{"cell_type":"code","source":["# YOUR CODES HERE for above practice exercise"],"metadata":{"id":"I1uzhaCN1enO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create a ChatPromptTemplate from a list of system and human messages with placeholders for {context} and {question}\n","#YOUR CODE HERE"],"metadata":{"id":"t4StVsQ7lQS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"What awards did Aryan Kapoor win for his contributions to the entertainment industry,\n","and in which years were they received?\"\"\"\n","context= \"\"\"\n","Meet Aryan Kapoor, a rising star in the entertainment industry whose talent knows no bounds. In 2023, Aryan captivated\n","audiences with his mesmerizing performance in the critically acclaimed film \"Echoes of Eternity,\" earning him the\n"," prestigious Best Actor award at the National Film Awards. His versatility shone brightly in 2024 when he showcased his\n","  vocal prowess as a playback singer in the chart-topping soundtrack of the blockbuster movie \"Infinite Horizon.\" The same year,\n","  Aryan's captivating screen presence garnered him the coveted Filmfare Critics Award for Best Actor. As his star continued to\n","  ascend, Aryan was honored with the International Icon of the Year award at the Global Entertainment Awards in 2025, recognizing\n","   his global impact and widespread admiration. With each role he undertakes, Aryan Kapoor cements his status as an unrivaled\n","   talent in the world of cinema, leaving audiences eagerly anticipating his next masterpiece.\n","\"\"\"\n","messages = chat_template.format_messages(context = context,  question=question)"],"metadata":{"id":"MN6-TQaliTMT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convert messages into a chat prompt\n","#YOUR CODE HERE"],"metadata":{"id":"5u6PwxIqjdfn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke chat_model with messages and print the content of the response\n","#YOUR CODE HERE"],"metadata":{"id":"hs-ph2ePAFb5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Output Parsers**\n","\n","Let's start with defining how we would like the LLM output to look like:"],"metadata":{"id":"7BPY4s_hGQv-"}},{"cell_type":"code","source":["# An example output format\n","{\n","  \"gift\": False,\n","  \"delivery_days\": 5,\n","  \"price_value\": \"pretty affordable!\"\n","}"],"metadata":{"id":"x1nyuc_1GO6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["customer_review = \"\"\"\\\n","This leaf blower is pretty amazing.  It has four settings:\\\n","candle blower, gentle breeze, windy city, and tornado. \\\n","It arrived in two days, just in time for my wife's \\\n","anniversary present. \\\n","I think my wife liked it so much she was speechless. \\\n","So far I've been the only one using it, and I've been \\\n","using it every other morning to clear the leaves on our lawn. \\\n","It's slightly more expensive than the other leaf blowers \\\n","out there, but I think it's worth it for the extra features.\n","\"\"\""],"metadata":{"id":"qW37-qdYGaOY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review_template = \"\"\"\\\n","For the following text, extract the following information:\n","\n","gift: Was the item purchased as a gift or present for someone else? \\\n","Answer True if yes, False if not or unknown.\n","\n","delivery_days: How many days did it take for the product \\\n","to arrive? If this information is not found, output -1.\n","\n","price_value: Extract any sentences about the value or price,\\\n","and output them as a comma separated Python list.\n","\n","Format the output as JSON with the following keys:\n","gift\n","delivery_days\n","price_value\n","\n","text: {text}\n","\"\"\""],"metadata":{"id":"ppJOtjsEGdL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","#Create a ChatPromptTemplate from review_template\n","#YOUR CODE HERE"],"metadata":{"id":"gQDimFP3Gp5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Format messages using prompt_template with text=customer_review, invoke chat_model with the messages, and print the response content\n","#YOUR CODE HERE\n"],"metadata":{"id":"MYur071rMz6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(response.content))"],"metadata":{"id":"cV1eVBvyHhfY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Parse the LLM output string into a structured data**::\n","\n"],"metadata":{"id":"Pf3bgzsf7pgP"}},{"cell_type":"markdown","source":["#### **Parse the LLM output string into a structured data**:\n","\n","\n","Language models output text. But there are times where you want to get more structured information than just text back. While some model providers support [built-in ways to return structured output](https://python.langchain.com/docs/how_to/structured_output/), not all do.\n","\n","Output parsers are classes that help structure language model responses.\n","\n","Below we go over the main type of output parser, the `PydanticOutputParser`.\n","\n","\n","\n"],"metadata":{"id":"CisHl2jWPfIR"}},{"cell_type":"markdown","source":["### [Structured Output](https://python.langchain.com/docs/how_to/structured_output/)"],"metadata":{"id":"d8N7zx3mCoIj"}},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","\n","# Pydantic\n","class produt_info(BaseModel):\n","    \"\"\" Product service info.\"\"\"\n","\n","    gift: str = Field(description=\"Was the item purchased\\\n","                             as a gift for someone else? \\\n","                             Answer True if yes,\\\n","                             False if not or unknown.\")\n","    delivery_days: int = Field(description=\"How many days\\\n","                                      did it take for the product\\\n","                                      to arrive? If this \\\n","                                      information is not found,\\\n","                                      output -1.\")\n","    price_value:str = Field(description=\"Extract any\\\n","                                    sentences about the value or \\\n","                                    price, and output them as a \\\n","                                    comma separated Python list.\"\n","    )"],"metadata":{"id":"EH0hArbY7n4t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up a parser + inject instructions into the prompt template\n","#YOUR CODE HERE"],"metadata":{"id":"E639itiwPmWR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{text}\\n\",\n","    input_variables=[\"text\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")"],"metadata":{"id":"5POs55z-PnRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# And a query intended to prompt a language model to populate the data structure.\n","#YOUR CODE HERE"],"metadata":{"id":"gYzXUgx3QF9w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(result.gift)\n","print(result.delivery_days)\n","print(result.price_value)"],"metadata":{"id":"u3BgDcCa7tcI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### [**Customizing Conversational Memory**](https://python.langchain.com/docs/how_to/chatbots_memory/)\n","\n","\n","LangChain can helps in building better chatbots, or have\n","an LLM with more effective chats by better managing\n","what it remembers from the conversation you've had so far."],"metadata":{"id":"Br30bwaPKs0N"}},{"cell_type":"code","source":["prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n","        ),\n","        (\"placeholder\", \"{chat_history}\"),\n","        (\"human\", \"{input}\"),\n","    ]\n",")\n","\n","chain = prompt | chat_model\n"],"metadata":{"id":"TBDcA56ovm_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory"],"metadata":{"id":"C1_WmMeZv1HV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["store = {}      # to store chat messages\n","\n","def get_session_history(session_id: str) -> ChatMessageHistory:\n","    if session_id not in store:\n","        store[session_id] = ChatMessageHistory()\n","    return store[session_id]\n","\n","\n","#Create a RunnableWithMessageHistory named chain_with_message_history that uses chain, retrieves session history with get_session_history,\n"," #and specifies keys for input and chat history messages\n"," #YOUR CODE HERE"],"metadata":{"id":"-zGGnVncvtWt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke chain_with_message_history with the input \"Hi, my name is James\" and a configurable session_id set to \"user1\"\n","#YOUR CODE HERE"],"metadata":{"id":"PTe4OV8Kwoat"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["store"],"metadata":{"id":"ALK5ZboQw53S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke chain_with_message_history with the input \"Do you remember my name?\" and a configurable session_id set to \"user1\"\n","#YOUR CODE HERE"],"metadata":{"id":"HQPxFgMEwz0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["store"],"metadata":{"id":"vsmS0nLgxdxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke chain_with_message_history with an input of \"Can you tell me what is my name?\" and a configuration that includes a session_id set to \"user1\"\n","#YOUR CODE HERE"],"metadata":{"id":"gbW0TdOVxef3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["store"],"metadata":{"id":"Wb2HR0MAvm3j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **II. mistralai/Mistral-7B-Instruct-v0.3**\n","\n","<font color='#990000'> **Note that you need to ask for access before using this model. Go to https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3 and click on \"Agree and access repository\".** </font>\n"],"metadata":{"id":"zSbCSUOfxXa-"}},{"cell_type":"code","source":["from langchain_huggingface import HuggingFaceEndpoint"],"metadata":{"id":"h_733Aai1RG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"How to learn programing? Give 5 examples. \""],"metadata":{"id":"_XZllnjBzqw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Instantiate a HuggingFaceEndpoint named llm using the repo_id \"mistralai/Mistral-7B-Instruct-v0.3\", a temperature of 0.5, and specific  max length and token\n","#YOUR CODE HERE"],"metadata":{"id":"-aqIG9-lyFdF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = llm.invoke(question)\n","print(response)"],"metadata":{"id":"bXJMBgfy0A5Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Prompt Template**\n","\n","**Example-1**"],"metadata":{"id":"OmRI-p9fp0SR"}},{"cell_type":"code","source":["from langchain.schema import (\n","    HumanMessage,\n","    SystemMessage,\n",")"],"metadata":{"id":"xiZNTCsGNpPC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate"],"metadata":{"id":"WnF-Qc_FrTZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template_s = \"\"\"You are a {style1}.\\\n","Tell me  {count} facts about {event_or_place}.```\n","\"\"\""],"metadata":{"id":"SHJWqMg3yxa_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Create a ChatPromptTemplate using template_s\n"," #YOUR CODE HERE"],"metadata":{"id":"wHucwPZ7yVPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Access the prompt of the first message in prompt_template.messages\n","#YOUR CODE HERE"],"metadata":{"id":"jH_lqJRbzaHt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_template.messages[0].prompt.input_variables"],"metadata":{"id":"fDyBeGD8zej9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Format user_messages using prompt_template with style1 set to \"knowledgeable historian\", count set to 5, and event_or_place set to \"Taj Mahal\"\n","#YOUR CODE HERE"],"metadata":{"id":"QXUiH0sszkUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_messages"],"metadata":{"id":"qP62G5bz0KBJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**<font color='#990000'> Note: Before running the below code cell, go to the following link and click on \"Agree and access repository\" button </font>**\n","\n","https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3"],"metadata":{"id":"-fPKnvLPp7Jj"}},{"cell_type":"code","source":["from langchain_huggingface import ChatHuggingFace\n","\n","#Create a ChatHuggingFace instance named chat_model using llm, and then access its model_id\n","#YOUR CODE HERE"],"metadata":{"id":"Q5IfurZcyYt8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the tokenizer from the repo_id used by the llm\n","tokenizer = AutoTokenizer.from_pretrained(llm.repo_id)\n","\n","# Initialize ChatHuggingFace with both llm and tokenizer\n","chat_model = ChatHuggingFace(llm=llm, tokenizer=tokenizer)\n","\n","# Now the chat_model should have a tokenizer and the following line should work\n","chat_model.model_id"],"metadata":{"id":"K6mtvjAYihkE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat_model._to_chat_prompt(user_messages)"],"metadata":{"id":"ybxEq_9JqywX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke chat_model with user_messages and print the content of the response\n","#YOUR CODE HERE"],"metadata":{"id":"SYI0aD8Hsty_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Example-2**"],"metadata":{"id":"wakjVUVZp2YH"}},{"cell_type":"code","source":["messages = [HumanMessage(content=\"How to learn programming? give 5 points\")]"],"metadata":{"id":"jiFDpiyENyOS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat_model._to_chat_prompt(messages)"],"metadata":{"id":"6SO2qIrju7rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke chat_model with messages and print the content of the response\n","#YOUR CODE HERE"],"metadata":{"id":"jEhKW2msODT2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **III.** **[Llama2](https://ai.meta.com/llama/)** ***(Optional)***\n","\n","**NOTE:**\n","\n",">For using this model you have to click `Download models` link available in [this](https://ai.meta.com/llama/) reference which re-direct to a **form for request**. It may take 1 hour to 2 days to get the **approval** for usage of this model through HuggingFace. You will get an email for the same.\n","\n",">Once the request is approved, connect to **GPU runtime** for below steps. Also, you need to provide your HF api key/access token.\n","\n","Trying Llama2-2-7b model:\n"],"metadata":{"id":"XaaC7-gu_KOK"}},{"cell_type":"code","source":["%%capture\n","!pip install -q transformers accelerate langchain xformers bitsandbytes"],"metadata":{"id":"HbzbpWIK_J4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Enter your HuggingFace access token when prompted\n","#Write code to Enter your HuggingFace access token when prompted\n","#YOUR CODE HERE"],"metadata":{"id":"zW69WOWSzwkG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initializing the Hugging Face Pipeline\n","\n","The first thing we need to do is initialize a `text-generation` pipeline with Hugging Face transformers. The Pipeline requires three things that we must initialize first, those are:\n","\n","* A LLM, in this case it will be `meta-llama/Llama-2-7b-chat-hf`.\n","\n","* The respective tokenizer for the model.\n","\n","We'll explain these as we get to them, let's begin with our model.\n","\n","We initialize the model and move it to our CUDA-enabled GPU. Using Colab this can take 5-10 minutes to download and initialize the model."],"metadata":{"id":"Rw7oXd2pAE1f"}},{"cell_type":"code","source":["from torch import cuda, bfloat16\n","import transformers"],"metadata":{"id":"--40_VMGJBEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Define the model_id as 'meta-llama/Llama-2-7b-chat-hf' and set the device to use CUDA if available, or fallback to CPU\n","#YOUR CODE HERE"],"metadata":{"id":"h49z-C1RJC9D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='#990000'> **Note: Before running the below code cell, go to the following link and execute the following steps.** </font>\n","\n","https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n","\n","**Step-1:** You need to share contact information with Meta to access this model\n","\n","**Step-2:** Under **'LLAMA 2 COMMUNITY LICENSE AGREEMENT'** section, click on **'Expand to review and access'** button.\n","\n","**Step-3:** Then fill up the form and finally check-in the check box for accepting the terms of the license.\n","\n","**Step-4:** Click on **'Submit'** button.\n","\n","**Step-5:** After submitting you need to wait till the owner has given you the access. **You will receive one email notification.**\n","\n"],"metadata":{"id":"ib-au6C_Qb1o"}},{"cell_type":"code","source":["tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n","\n","pipeline = transformers.pipeline(\n","    \"text-generation\",\n","    model=model_id,\n","    tokenizer=tokenizer,\n","    torch_dtype=bfloat16,\n","    trust_remote_code=True,\n","    device_map=\"auto\",\n","    max_length=1000,\n","    do_sample=True,\n","    top_k=10,\n","    num_return_sequences=1,\n","    eos_token_id=tokenizer.eos_token_id\n","    )"],"metadata":{"id":"T2Cp6jnomS0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = pipeline(\"How to learn programming?\")\n","print(res[0][\"generated_text\"])"],"metadata":{"id":"8n7MjpX4nM-r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Now implementing with LangChain**"],"metadata":{"id":"IzqImT9RAdAg"}},{"cell_type":"code","source":["!pip -q install langchain\n","!pip -q install langchain_community"],"metadata":{"id":"hLkLetCxWF-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.llms import HuggingFacePipeline\n","\n","#Create an instance of HuggingFacePipeline named llm using a specified pipeline and setting the model_kwargs with a temperature of 0.7\n","#YOUR CODE HERE"],"metadata":{"id":"h71jByoBAffB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Invoke the llm model with the question \"How to learn programming?\" and print the result\n","#YOUR CODE HERE"],"metadata":{"id":"2tr-YGpvnr0X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Prompt Template**"],"metadata":{"id":"prWXot8wcKyS"}},{"cell_type":"code","source":["from langchain.prompts import ChatPromptTemplate"],"metadata":{"id":"7DTl7I1HaOJK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template_s = \"\"\"Reply  the answer \\\n","like  {style1}. \\\n","text: ```{text1}```\n","\"\"\""],"metadata":{"id":"mqU1EAehaOJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create a ChatPromptTemplate using the string template_s\n","#YOUR CODE HERE"],"metadata":{"id":"YK6fMe1paOJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_template.messages[0].prompt"],"metadata":{"id":"R5AlexzxaOJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Access the input_variables of the prompt in the first message of prompt_template.messages\n"," #YOUR CODE HERE"],"metadata":{"id":"bJa3nBfbaOJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["style = \"\"\"trustworthy friend\"\"\""],"metadata":{"id":"dYlQrFsnaOJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query = \"\"\"\n","I am not able to understand the concept taught in class. \\\n","Could you please suggest something? \\\n","I need your help. Give 5 points to work on.\n","\"\"\""],"metadata":{"id":"D9UtT3reaOJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_messages = prompt_template.format_messages(\n","                    style1=style,\n","                    text1=query)"],"metadata":{"id":"AUB4HHQTaOJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(user_messages[0])"],"metadata":{"id":"6r6WC6OZaOJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Call the LLM to translate to the style of the customer message\n","#YOUR CODE HERE"],"metadata":{"id":"w-zPBqhKaOJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(llm_response)"],"metadata":{"id":"2sMDbkrmoIs_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ErjQyyi4nR2n"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"VgSwVENIPcM6"},"source":["#@title Which of the following prompt techniques in LangChain allows flexible templated prompts that are suitable for better describing the role and content? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer = \"\" #@param [\"\", \"PromptTemplate\", \"ChatPromptTemplate\", \"Both\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW"},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]}]}