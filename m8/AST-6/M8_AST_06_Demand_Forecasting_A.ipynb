{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["-Be2S_PBH6Qj"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WFBl3DsqB3AE"},"source":["# Advanced Certification Program in Computational Data Science\n","\n","##  A program by IISc and TalentSprint\n","\n","### Assignment 6: Demand Forecasting"]},{"cell_type":"markdown","metadata":{"id":"maritime-miami"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"95F1ym6qB8VU"},"source":["At the end of the experiment, you will be able to :\n","\n","* perform EDA and analyze the feature importance of sales data\n","* prepare the data for forecasting task\n","* solve the problem of Demand Planning Optimization\n","* implement ARIMA model to forecast the demands of a sales"]},{"cell_type":"markdown","metadata":{"id":"-Be2S_PBH6Qj"},"source":["## Information\n","\n","Sales forecasting is an approach retailers use to anticipate future sales by analyzing past sales, identifying trends, and projecting data into the future. The simplest version of a sales forecast will look at sales in Store A during last year, assume a continuation of some multi-year trend for Store A (e.g. some percentage of growth or decline in sales), and project forward to predict sales in Store A this year.\n","\n","Sales forecasting has been the standard approach to retailing from the beginning of the industry itself.\n","\n","Although modern retailers have more data than ever (as well as new tools and business intelligence dashboards), and can easily leverage more advanced and accurate forms of forecasting, sales-based forecasting is still the backbone of most retail organizations.\n","\n","some benefits of having an accurate sales forecast\n","\n","* Improved decision-making about the future\n","* Reduction of sales pipeline and forecast risks\n","* Alignment of sales quotas and revenue expectations\n","* Reduction of time spent planning territory coverage and setting quota assignments\n","* Benchmarks that can be used to assess trends in the future\n","* Ability to focus a sales team on high-revenue, high-profit sales pipeline  opportunities, resulting in improved win rates\n","\n","\n","This Demand optimization can reduce operational costs by:\n","\n","**Inventory Optimization:** matching store inventory with actual needs to reduce storage space needed (Rental Costs)\n","\n","**Replenishment Optimization:** optimizing replenishment quantity per order to minimize the number of replenishments between warehouse and stores (Warehousing & Transportation Costs)\n"]},{"cell_type":"markdown","metadata":{"id":"NVcis_FNIrFY"},"source":["## Dataset\n","\n","Store Item Demand Forecasting dataset consists of 5 years of store-item sales data from the year 2013 to 2017. It contains sales for 50 different items at 10 different stores with 913000 observations and 4 columns Date Store, item, sales.\n","\n","Attributes information:\n","\n","**Date:** Date starting from 2013 to 2017\n","\n","**Store:** Store indicating with a number\n","\n","**Item:** Item  in a store\n","\n","**Sales:** No.of sales"]},{"cell_type":"markdown","metadata":{"id":"BNLA8HiKxQhc"},"source":["### Setup Steps:"]},{"cell_type":"code","metadata":{"id":"2YzfoPvJDiTX"},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjoZJWGErxGf"},"source":["#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBPPuGmBlDIN","cellView":"form"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","\n","notebook= \"M8_AST_06_Demand_Forecasting_A\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx pip -qq install pmdarima\")\n","    ipython.magic(\"sx wget https://raw.githubusercontent.com/insaid2018/Term-3/master/Projects/Store_Item_demand_forecast.csv\")\n","\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","\n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n","              \"concepts\" : Concepts, \"record_id\" : submission_id,\n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_mentor_support\": Mentor_support}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://learn-iisc.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","\n","\n","def getAdditional():\n","  try:\n","    if not Additional:\n","      raise NameError\n","    else:\n","      return Additional\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","\n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","\n","# def getWalkthrough():\n","#   try:\n","#     if not Walkthrough:\n","#       raise NameError\n","#     else:\n","#       return Walkthrough\n","#   except NameError:\n","#     print (\"Please answer Walkthrough Question\")\n","#     return None\n","\n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","\n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError\n","    else:\n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","\n","def getId():\n","  try:\n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup\n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YRIzMfgjwcAp"},"source":["### Import required packages"]},{"cell_type":"code","metadata":{"id":"34ccJLc6amaQ"},"source":["!pip install numpy==1.26.4\n","import warnings\n","warnings.simplefilter('ignore')\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","from statsmodels.tsa.stattools import adfuller, kpss\n","import statsmodels.api as sm\n","from scipy import stats\n","from scipy.stats import normaltest\n","import pmdarima as pm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmyc9n2Kaq1W"},"source":["### Load the data"]},{"cell_type":"code","metadata":{"id":"evVDmG9xClM9"},"source":["dataset  =  pd.read_csv('Store_Item_demand_forecast.csv')\n","dataset.head(), dataset.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sample_set(dataset, store, item):\n","  return dataset[(dataset.store == store) & (dataset.item == item)].reset_index()['sales']"],"metadata":{"id":"mqKb0xiWIey2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1mcTf_DQMeuH"},"source":["### ARIMA Analysis"]},{"cell_type":"markdown","metadata":{"id":"s10cHNT1HamP"},"source":["#### Decomposition\n","\n","Time series data can be broken down into four core components: the average value, a trend (i.e. an increasing mean), seasonality (i.e. a repeating cyclical pattern), and a residual (random noise). Trends and seasonality are not always present in time dependent data. The residual is what’s left over after trends and seasonality are removed. Time series models assume that the data is stationary and only the residual component satisfies the conditions for stationarity.\n","\n","Python’s statsmodels library has a method for time series decomposition called `seasonal_decompose()`.\n","\n","* Apply decomposition and plot the trend, seasonality and residual"]},{"cell_type":"markdown","source":["To know more about `seasonal_decompose()`function click [here](https://www.statsmodels.org/devel/generated/statsmodels.tsa.seasonal.seasonal_decompose.html)"],"metadata":{"id":"1KnmYa8U5xbx"}},{"cell_type":"code","source":["sample = sample_set(dataset, store = 1, item = 1)"],"metadata":{"id":"UIMb3Zp63lml"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VMcbh3Sp82Pz"},"source":["# Decomposition of time series\n","result = seasonal_decompose(x=sample, model='additive', filt=None, period=365, two_sided=False)\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3wtOuH7jtqG"},"source":["#### Stationarity\n","\n","If a time series is stationary and has a particular behavior over a given time interval, then it is safe to assume that it will have same behavior at some later point in time. Most statistical modeling methods assume or require the time series to be stationary.\n","\n","**What is variance?**\n","\n","Variance is a measurement of the spread between numbers in a data set. The variance measures how far each number in the set is from the mean. The square root of variance is the standard deviation.\n","\n","**How to check Whether data is Stationary or not?**\n","\n","There are two ways we can check the stationarity of a time series. The first is by looking at the data. By visualizing the data it should be easy to identify a changing mean or variation in the data. For a more accurate assessment, there are tests available such as, the Dickey-Fuller test, and  the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test. For Dickey-Fuller test, if the ‘Test Statistic’ is greater than the ‘Critical Value’ then the time series is stationary while for KPSS test, if the test statistic is greater than the critical value then the time series is not stationary.\n","\n","It is always better to apply both the tests, so that it can be ensured that the series is truly stationary. Possible outcomes of applying these stationary tests are as follows:\n","\n","- Case 1: Both tests conclude that the series is not stationary - The series is not stationary\n","\n","- Case 2: Both tests conclude that the series is stationary - The series is stationary\n","\n","- Case 3: KPSS indicates stationarity and ADF indicates non-stationarity - The series is trend stationary. Trend needs to be removed to make series strict stationary. The detrended series is checked for stationarity.\n","\n","- Case 4: KPSS indicates non-stationarity and ADF indicates stationarity - The series is difference stationary. Differencing is to be used to make series stationary. The differenced series is checked for stationarity.\n","\n","To know more about ADF and KPSS tests, refer [here](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html).\n","\n","Implement a function which takes a timeseries as input and perform:\n","  * Rolling mean and rolling standard and plot it with a graph\n","  * Dicky fuller test and check p-value\n","  * Kwiatkowski-Phillips-Schmidt-Shin test and check p-value\n"]},{"cell_type":"code","metadata":{"id":"zDagt3dTFdQs"},"source":["# Create function to test stationarity\n","def test_stationarity(timeseries, window = 12):\n","\n","    # Determing rolling statistics\n","    rolmean = timeseries.rolling(window).mean()\n","    # YOUR CODE HERE to create 'rolstd'\n","\n","    # Plot rolling statistics:\n","    fig = plt.figure(figsize=(12, 8))\n","    orig = plt.plot(timeseries, color='blue',label='Original')\n","    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n","    # YOUR CODE HERE to create 'std' by plotting (rolstd, color='black', label = 'Rolling Std')\n","    plt.legend(loc='best')\n","    plt.title('Rolling Mean & Standard Deviation')\n","    plt.show()\n","\n","test_stationarity(sample[:10000])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the above plot, the series looks non-stationary.\n","\n","Let us also test the stationarity with:\n","- adfuller test\n","- KPSS test"],"metadata":{"id":"OaJjjUTM_RUb"}},{"cell_type":"markdown","metadata":{"id":"mOuqD9kIEhru"},"source":["#### Dickey-Fuller test"]},{"cell_type":"code","source":["# Perform Dickey-Fuller test on original series:\n","\n","print('Results of Dickey-Fuller Test:')\n","dftest = adfuller(sample[:10000])\n","dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n","for key,value in dftest[4].items():\n","    dfoutput['Critical Value (%s)'%key] = value\n","pvalue = dftest[1]\n","if pvalue < 0.01:\n","    print('p-value = %.4f. The series is likely stationary.' % pvalue)\n","else:\n","    print('p-value = %.4f. The series is likely non-stationary.' % pvalue)\n","\n","print(dfoutput)"],"metadata":{"id":"aseGFe9Nngva"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the above results, we can see that the ADF test shows the series is stationary. Let's check KPSS test for further confirmation."],"metadata":{"id":"mlpcULYRAfjW"}},{"cell_type":"markdown","source":["### Kwiatkowski-Phillips-Schmidt-Shin test"],"metadata":{"id":"PB2hxD8Ku6Bm"}},{"cell_type":"code","source":["# Perform KPSS test on original series:\n","\n","result = kpss(sample[:10000])\n","print(result)\n","print('KPSS Test Statistic: %.2f' % result[0])\n","print('5%% Critical Value: %.2f' % result[3]['5%'])\n","print('p-value: %.2f' % result[1])"],"metadata":{"id":"jdRMDE-Mu8v-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As we can see, the p-value is less than 0.05. We reject the null hypothesis and conclude that the time **series is not stationary**.\n","\n","From both the tests results, we see that for the actual series the KPSS indicates non-stationarity and ADF indicates stationarity. So, the Case-4 will be applied i.e, the series is difference stationary. Differencing is to be used to make series stationary then the differenced series is checked again for stationarity."],"metadata":{"id":"R66PBQwPvNdw"}},{"cell_type":"markdown","metadata":{"id":"DZrKDVcpEhr4"},"source":["Differencing the data with shift 1 and testing stationarity"]},{"cell_type":"code","metadata":{"id":"iZHGFMqbEhr5"},"source":["# differencing the data\n","diff = sample[:10000].diff(1).fillna(0)\n","# YOUR CODE HERE to test stationarity for 'diff' series"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the above plot, the rolling mean and standard deviation are more stable now."],"metadata":{"id":"9XHGqlyFA23y"}},{"cell_type":"code","metadata":{"id":"RmcacpIAEhr5"},"source":["# Perform Dickey-Fuller test on differenced series:\n","\n","print('Results of Dickey-Fuller Test:')\n","dftest = adfuller(diff)\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ADF test shows the series is stationary after differencing. Let's check KPSS test for further confirmation."],"metadata":{"id":"lY3GbVj43byG"}},{"cell_type":"code","source":["# Perform KPSS test on differenced series:\n","\n","result = kpss(diff)\n","# YOUR CODE HERE"],"metadata":{"id":"ufE63BLEvP00"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As we can see, the p-value is greater than 0.05. We fail to reject the null hypothesis and conclude that the time **series is stationary**.\n","\n","So now, both the tests shows that the differenced series is stationary."],"metadata":{"id":"cKkpMxS0vdw5"}},{"cell_type":"markdown","metadata":{"id":"OGP-Mgd5E1jr"},"source":["### Autoregression Intuition\n","\n","Consider a time series that was generated by an autoregression (AR) process with a lag of k.\n","\n","We know that the ACF describes the autocorrelation between an observation and another observation at a prior time step that includes direct and indirect dependence information.\n","\n","This means we would expect the ACF for the AR(k) time series to be strong to a lag of k and the inertia of that relationship would carry on to subsequent lag values, trailing off at some point as the effect was weakened.\n","\n","We know that the PACF only describes the direct relationship between an observation and its lag. This would suggest that there would be no correlation for lag values beyond k.\n","\n","This is exactly the expectation of the ACF and PACF plots for an AR(k) process.\n","\n","### Moving Average Intuition\n","\n","Consider a time series that was generated by a moving average (MA) process with a lag of k.\n","\n","Remember that the moving average process is an autoregression model of the time series of residual errors from prior predictions. Another way to think about the moving average model is that it corrects future forecasts based on errors made in recent forecasts.\n","\n","We would expect the ACF for the MA(k) process to show a strong correlation with recent values up to the lag of k, then a sharp decline to low or no correlation. By definition, this is how the process was generated.\n","\n","For the PACF, we would expect the plot to show a strong relationship to the lag and a trailing off of correlation from the lag onwards.\n","\n","Again, this is exactly the expectation of the ACF and PACF plots for an MA(k) process.\n","\n","**Summary:**\n","From the autocorrelation plot we can tell whether or not we need to add MA terms. From the partial autocorrelation plot, we know we need to add AR terms.\n","\n","References:\n","https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/"]},{"cell_type":"markdown","metadata":{"id":"_B6OZawO4nG2"},"source":["### How to interpret ACF and PACF plots\n","\n","For time series models such as Auto Regression (AR), Moving Averages (MA), or their combinations (ARMA), we need to specify one or more parameters (eg. p, q). These can be obtained by looking at ACF (to infer q parameter) and PACF (to infer p parameter) plots.\n","\n","In a nutshell:\n","\n","* If the ACF plot declines gradually and the PACF drops instantly, use Auto Regressive model\n","* If the ACF plot drops instantly and the PACF declines gradually, use Moving Average model\n","* If both ACF and PACF decline gradually, combine Auto Regressive and Moving Average models (ARMA).\n"]},{"cell_type":"code","metadata":{"id":"VgcKqpaA-Bc3"},"source":["# Visualize ACF and PACF plots\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To know more about ARIMA click [here](https://www.statsmodels.org/devel/generated/statsmodels.tsa.arima.model.ARIMA.html)"],"metadata":{"id":"_LV2w8DV5qRr"}},{"cell_type":"code","metadata":{"id":"clERqC_b-VpG"},"source":["# YOUR CODE HERE for ARIMA"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uI5s5cMNmqFN"},"source":["The summary attribute that results from the output of ARIMA returns a significant amount of information,\n","\n","* The coef column shows the weight (i.e. importance) of each feature and how each one impacts the time series.\n","* The P>|z| column informs us of the significance of each feature weight. Here, each weight has a p-value lower or close to 0.05, so it is reasonable to retain all of them in our model."]},{"cell_type":"markdown","metadata":{"id":"gOGm-y-XLmH2"},"source":["Reading ACF and PACF plots is however still challenging, and using grid search to find optimal parameter values is sometimes useful. From grid search, we can obtain an optimal parameter combination that has the lowest error (such as MAPE) or lowest general quality estimator (such as AIC).\n"]},{"cell_type":"markdown","metadata":{"id":"MpOzzl6xLdB4"},"source":["### Identifying optimal parameters using `auto_arima`\n","\n","pmdarima‘s `auto_arima` function is extremely useful when building an ARIMA model as it helps us identify the most optimal p,d,q parameters and return a fitted ARIMA model.\n","\n","**Using pmdarima for Auto ARIMA model:**\n","\n","In the previous method, checking for stationarity, making data stationary if necessary, and determining the values of p and q using the ACF/PACF plots can be time-consuming and less efficient. Using pmdarima’s auto_arima() function makes this task easier for us by eliminating steps for implementing an ARIMA model.\n","\n","\n","#### auto_arima\n","\n","The auto-ARIMA process seeks to identify the most optimal parameters for an ARIMA model, settling on a single fitted ARIMA model.\n","\n","Auto-ARIMA works by conducting differencing tests (i.e., Kwiatkowski–Phillips–Schmidt–Shin, Augmented Dickey-Fuller or Phillips–Perron) to determine the order of differencing, d, and then fitting models within ranges of defined start_p, max_p, start_q, max_q ranges. If the seasonal optional is enabled, auto-ARIMA also seeks to identify the optimal P and Q hyper- parameters after conducting the Canova-Hansen to determine the optimal order of seasonal differencing, D.\n","\n","In order to find the best model, auto-ARIMA optimizes for a given information_criterion, one of (‘aic’, ‘aicc’, ‘bic’, ‘hqic’, ‘oob’) (Akaike Information Criterion, Corrected Akaike Information Criterion, Bayesian Information Criterion, Hannan-Quinn Information Criterion, or “out of bag”–for validation scoring–respectively) and returns the ARIMA which minimizes the value.\n","\n","**Note:** pmdarima may take a long time to find the terms for the dataset, subset of datapoints are used to minimize the execution time, however, we can experiment with a subset of the dataset.\n","\n","\n","From the ACF and PACF plot, we can observe that data is exhibiting same pattern for each 7 lags. (seasonal term 'm' = 7)"]},{"cell_type":"code","source":["# Fit the model\n","model = pm.auto_arima(sample[:1000], seasonal=True, m=7) # m is seasonal term\n","\n","# YOUR CODE HERE for forecast"],"metadata":{"id":"-OkCtugptWPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0jRkqQb0ib5"},"source":["# Model summary\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHfHdGCP_n6Y"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"VgSwVENIPcM6"},"source":["#@title Time-series analysis is based on the assumption that { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer = \"\" #@param [\"\", \"random error terms are normally distributed.\", \"past patterns in the variable to be forecast will continue unchanged into the future.\", \"the data do not exhibit a trend.\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW"},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]}]}